{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Concept GNN Pipeline – Colab GPU A100", 
    "\n", 
    "Ce notebook orchestre l'intégralité du pipeline (génération, entraînement, évaluation) à partir du repo GitHub **pascalseppey/concept-gnn-pipeline**. Chaque étape est isolée pour validation avant launch massive." ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prerequisites"
   },
   "source": [
    "## 1. Pré-requis", 
    "- Runtime Colab : **GPU A100** (Runtime > Modifier le type de matériel).", 
    "- Repo GitHub : `https://github.com/pascalseppey/concept-gnn-pipeline.git`." ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gpu"
   },
   "source": [ "!nvidia-smi" ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [ "## 2. Cloner le repo et installer les dépendances" ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "clone"
   },
   "source": [
    "REPO_URL = \"https://github.com/pascalseppey/concept-gnn-pipeline.git\"\n",
    "REPO_DIR = \"/content/concept-gnn-pipeline\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone --depth 1 {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    %cd {REPO_DIR}\n",
    "    !git pull\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!pip install -U pip\n",
    "!pip install -r requirements.txt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": { "id": "configs" },
   "source": ["## 3. Inspecter / adapter les configs" ]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "show-config"},
   "source": ["!ls config\n", "!cat config/bins.yml"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "sweep"},
   "source": ["## 4. Balayage métrique déterministe"]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "run-sweep"},
   "source": ["!python scripts/effect_metric_sweep.py --config config/bins.yml --output data/logs/effect_metric_sweep.csv\n", "!head -n 5 data/logs/effect_metric_sweep.csv"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "dataset"},
   "source": ["## 5. Génération dataset (couverture contrôlée)"]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "gen-dataset"},
   "source": ["DATASET_PATH = 'data/logs/train_dataset.jsonl'\n", "!python scripts/generate_dataset.py --config config/generator.yml --max-samples 20000 --coverage-threshold 0.7 --min-per-bin 20 --output {DATASET_PATH}"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "inspect"},
   "source": ["## 6. Inspection rapide du dataset"]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "inspect1"},
   "source": ["import json\nimport pandas as pd\nrecords = []\nwith open(DATASET_PATH) as f:\n    for idx, line in enumerate(f):\n        if idx >= 5000: break\n        rec = json.loads(line)\n        metrics = rec['metrics']\n        metrics['sequence_id'] = rec['sequence_id']\n        records.append(metrics)\n\ndf = pd.DataFrame(records)\ndf.describe()"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {"id": "inspect2"},
   "source": ["import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(6,4))\nsns.histplot(df['fft_anisotropy'], bins=30)\nplt.title('Anisotropie FFT')\nplt.show()"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "train"},
   "source": ["## 7. Entraînement GNN"]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "train"},
   "source": ["LOG_DIR = 'data/logs/run_colab'\n!python scripts/train_gnn.py --config config/train.yml --dataset {DATASET_PATH} --log-dir {LOG_DIR} --epochs 20 --checkpoint-every 5"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "monitor"},
   "source": ["## 8. Suivi des métriques"]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "plot"},
   "source": ["import json\nimport matplotlib.pyplot as plt\nrecords = [json.loads(line) for line in open(f'{LOG_DIR}/metrics_log.jsonl')]\nepochs = [r['epoch'] for r in records]\ntrain_loss = [r['train_loss'] for r in records]\ntrain_acc = [r['train_acc'] for r in records]\nval_acc = [r['val_acc'] for r in records]\nfig, ax1 = plt.subplots(figsize=(7,4))\nax1.plot(epochs, train_loss, color='tab:red', label='Loss')\nax2 = ax1.twinx()\nax2.plot(epochs, train_acc, color='tab:blue', label='Train Acc')\nax2.plot(epochs, val_acc, color='tab:green', label='Val Acc')\nfig.legend(loc='upper center', bbox_to_anchor=(0.5,1.1), ncol=3)\nplt.show()"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "eval"},
   "source": ["## 9. Évaluation & Inversion"]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "evaluate"},
   "source": ["!python scripts/evaluate_gnn.py --checkpoint {LOG_DIR}/ckpt_epoch20.pt --dataset data/logs/train_dataset.jsonl --topk 5"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "export"},
   "source": ["## 10. Export des artifacts"]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "archive"},
   "source": ["!tar -czf run_colab_artifacts.tar.gz {LOG_DIR} data/logs/effect_metric_sweep.csv\nfrom google.colab import files\nfiles.download('run_colab_artifacts.tar.gz')"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "next"},
   "source": ["## 11. Prochaines étapes", "- Ajuster la génération (max-samples, coverage).", "- Étendre l'architecture (attention multi-échelle, multi-head).", "- Passer en streaming multi-GPU (GH200/H100).", "- Intégrer inversion/estimation WebP dans un service production." ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "concept_gnn_pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
